{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b505586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def reshape_to_wide(df):\n",
    "    id_cols = ['ESN', 'Cycles_Since_New'] \n",
    "    static_cols = ['Cumulative_WWs', 'Cumulative_HPC_SVs', 'Cumulative_HPT_SVs',\n",
    "                   'Cycles_to_WW', 'Cycles_to_HPC_SV', 'Cycles_to_HPT_SV']\n",
    "    sensor_cols = [c for c in df.columns if c not in id_cols + static_cols + ['Snapshot']]\n",
    "\n",
    "    df_wide = df.pivot_table(\n",
    "        index=id_cols, \n",
    "        columns='Snapshot', \n",
    "        values=sensor_cols\n",
    "    )\n",
    "\n",
    "    df_wide.columns = [f\"{col}_SS{snap}\" for col, snap in df_wide.columns]\n",
    "    \n",
    "    df_static = df.groupby(id_cols)[static_cols].first()\n",
    "    \n",
    "    final_df = df_wide.join(df_static).reset_index()\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85958dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESN</th>\n",
       "      <th>Cycles_Since_New</th>\n",
       "      <th>Sensed_Altitude_SS1</th>\n",
       "      <th>Sensed_Altitude_SS2</th>\n",
       "      <th>Sensed_Altitude_SS3</th>\n",
       "      <th>Sensed_Altitude_SS4</th>\n",
       "      <th>Sensed_Altitude_SS5</th>\n",
       "      <th>Sensed_Altitude_SS6</th>\n",
       "      <th>Sensed_Altitude_SS7</th>\n",
       "      <th>Sensed_Altitude_SS8</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensed_WFuel_SS5</th>\n",
       "      <th>Sensed_WFuel_SS6</th>\n",
       "      <th>Sensed_WFuel_SS7</th>\n",
       "      <th>Sensed_WFuel_SS8</th>\n",
       "      <th>Cumulative_WWs</th>\n",
       "      <th>Cumulative_HPC_SVs</th>\n",
       "      <th>Cumulative_HPT_SVs</th>\n",
       "      <th>Cycles_to_WW</th>\n",
       "      <th>Cycles_to_HPC_SV</th>\n",
       "      <th>Cycles_to_HPT_SV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.0000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>3674.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3633.000000</td>\n",
       "      <td>7914.000000</td>\n",
       "      <td>7914.000000</td>\n",
       "      <td>7914.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "      <td>8004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.500000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>722.538926</td>\n",
       "      <td>777.957217</td>\n",
       "      <td>7896.633379</td>\n",
       "      <td>20443.529056</td>\n",
       "      <td>29765.319746</td>\n",
       "      <td>26947.427357</td>\n",
       "      <td>26969.804543</td>\n",
       "      <td>26962.724833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484201</td>\n",
       "      <td>0.523060</td>\n",
       "      <td>0.498605</td>\n",
       "      <td>0.483981</td>\n",
       "      <td>9.561969</td>\n",
       "      <td>0.739755</td>\n",
       "      <td>2.235007</td>\n",
       "      <td>491.927786</td>\n",
       "      <td>3812.687406</td>\n",
       "      <td>1682.491254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.118104</td>\n",
       "      <td>5776.7496</td>\n",
       "      <td>884.366464</td>\n",
       "      <td>882.809931</td>\n",
       "      <td>9362.584213</td>\n",
       "      <td>405.038595</td>\n",
       "      <td>773.699297</td>\n",
       "      <td>3714.554671</td>\n",
       "      <td>3704.166238</td>\n",
       "      <td>3708.350008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213515</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0.059421</td>\n",
       "      <td>0.065380</td>\n",
       "      <td>5.823621</td>\n",
       "      <td>0.731378</td>\n",
       "      <td>1.739967</td>\n",
       "      <td>291.861312</td>\n",
       "      <td>2457.224970</td>\n",
       "      <td>1073.631703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-489.554524</td>\n",
       "      <td>-435.554524</td>\n",
       "      <td>-53.678484</td>\n",
       "      <td>18999.445476</td>\n",
       "      <td>28999.445476</td>\n",
       "      <td>19954.321516</td>\n",
       "      <td>19946.280264</td>\n",
       "      <td>19941.321516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101.750000</td>\n",
       "      <td>5000.0000</td>\n",
       "      <td>343.321516</td>\n",
       "      <td>401.321516</td>\n",
       "      <td>2719.280264</td>\n",
       "      <td>20219.554225</td>\n",
       "      <td>29002.280264</td>\n",
       "      <td>23004.321516</td>\n",
       "      <td>23002.321516</td>\n",
       "      <td>23004.554225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467751</td>\n",
       "      <td>0.472183</td>\n",
       "      <td>0.461201</td>\n",
       "      <td>0.446566</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>1660.000000</td>\n",
       "      <td>770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>102.500000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>611.554225</td>\n",
       "      <td>670.554225</td>\n",
       "      <td>3265.321516</td>\n",
       "      <td>20483.445476</td>\n",
       "      <td>30022.383496</td>\n",
       "      <td>28005.280264</td>\n",
       "      <td>28000.321516</td>\n",
       "      <td>28004.321516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485161</td>\n",
       "      <td>0.511504</td>\n",
       "      <td>0.495354</td>\n",
       "      <td>0.485301</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>3585.000000</td>\n",
       "      <td>1595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103.250000</td>\n",
       "      <td>15000.0000</td>\n",
       "      <td>887.445476</td>\n",
       "      <td>946.445476</td>\n",
       "      <td>5565.554225</td>\n",
       "      <td>20738.280264</td>\n",
       "      <td>30497.098754</td>\n",
       "      <td>29016.379693</td>\n",
       "      <td>29012.321516</td>\n",
       "      <td>29014.554225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.561556</td>\n",
       "      <td>0.534901</td>\n",
       "      <td>0.524295</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>5790.000000</td>\n",
       "      <td>2480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>20000.0000</td>\n",
       "      <td>7922.445476</td>\n",
       "      <td>7962.445476</td>\n",
       "      <td>35001.554225</td>\n",
       "      <td>21009.554225</td>\n",
       "      <td>31002.554225</td>\n",
       "      <td>35018.554225</td>\n",
       "      <td>35010.554225</td>\n",
       "      <td>35019.554225</td>\n",
       "      <td>...</td>\n",
       "      <td>11.905331</td>\n",
       "      <td>19.420420</td>\n",
       "      <td>0.713363</td>\n",
       "      <td>0.692309</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>9530.000000</td>\n",
       "      <td>4790.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ESN  Cycles_Since_New  Sensed_Altitude_SS1  \\\n",
       "count  8004.000000         8004.0000          8004.000000   \n",
       "mean    102.500000        10000.0000           722.538926   \n",
       "std       1.118104         5776.7496           884.366464   \n",
       "min     101.000000            0.0000          -489.554524   \n",
       "25%     101.750000         5000.0000           343.321516   \n",
       "50%     102.500000        10000.0000           611.554225   \n",
       "75%     103.250000        15000.0000           887.445476   \n",
       "max     104.000000        20000.0000          7922.445476   \n",
       "\n",
       "       Sensed_Altitude_SS2  Sensed_Altitude_SS3  Sensed_Altitude_SS4  \\\n",
       "count          8004.000000          8004.000000          8004.000000   \n",
       "mean            777.957217          7896.633379         20443.529056   \n",
       "std             882.809931          9362.584213           405.038595   \n",
       "min            -435.554524           -53.678484         18999.445476   \n",
       "25%             401.321516          2719.280264         20219.554225   \n",
       "50%             670.554225          3265.321516         20483.445476   \n",
       "75%             946.445476          5565.554225         20738.280264   \n",
       "max            7962.445476         35001.554225         21009.554225   \n",
       "\n",
       "       Sensed_Altitude_SS5  Sensed_Altitude_SS6  Sensed_Altitude_SS7  \\\n",
       "count          3674.000000          8004.000000          8004.000000   \n",
       "mean          29765.319746         26947.427357         26969.804543   \n",
       "std             773.699297          3714.554671          3704.166238   \n",
       "min           28999.445476         19954.321516         19946.280264   \n",
       "25%           29002.280264         23004.321516         23002.321516   \n",
       "50%           30022.383496         28005.280264         28000.321516   \n",
       "75%           30497.098754         29016.379693         29012.321516   \n",
       "max           31002.554225         35018.554225         35010.554225   \n",
       "\n",
       "       Sensed_Altitude_SS8  ...  Sensed_WFuel_SS5  Sensed_WFuel_SS6  \\\n",
       "count          8004.000000  ...       3633.000000       7914.000000   \n",
       "mean          26962.724833  ...          0.484201          0.523060   \n",
       "std            3708.350008  ...          0.213515          0.260859   \n",
       "min           19941.321516  ...          0.000000          0.000000   \n",
       "25%           23004.554225  ...          0.467751          0.472183   \n",
       "50%           28004.321516  ...          0.485161          0.511504   \n",
       "75%           29014.554225  ...          0.504038          0.561556   \n",
       "max           35019.554225  ...         11.905331         19.420420   \n",
       "\n",
       "       Sensed_WFuel_SS7  Sensed_WFuel_SS8  Cumulative_WWs  Cumulative_HPC_SVs  \\\n",
       "count       7914.000000       7914.000000     8004.000000         8004.000000   \n",
       "mean           0.498605          0.483981        9.561969            0.739755   \n",
       "std            0.059421          0.065380        5.823621            0.731378   \n",
       "min            0.226675          0.000000        0.000000            0.000000   \n",
       "25%            0.461201          0.446566        4.000000            0.000000   \n",
       "50%            0.495354          0.485301       10.000000            1.000000   \n",
       "75%            0.534901          0.524295       15.000000            1.000000   \n",
       "max            0.713363          0.692309       20.000000            2.000000   \n",
       "\n",
       "       Cumulative_HPT_SVs  Cycles_to_WW  Cycles_to_HPC_SV  Cycles_to_HPT_SV  \n",
       "count         8004.000000   8004.000000       8004.000000       8004.000000  \n",
       "mean             2.235007    491.927786       3812.687406       1682.491254  \n",
       "std              1.739967    291.861312       2457.224970       1073.631703  \n",
       "min              0.000000      0.000000          0.000000          0.000000  \n",
       "25%              1.000000    240.000000       1660.000000        770.000000  \n",
       "50%              2.000000    490.000000       3585.000000       1595.000000  \n",
       "75%              4.000000    740.000000       5790.000000       2480.000000  \n",
       "max              6.000000   1160.000000       9530.000000       4790.000000  \n",
       "\n",
       "[8 rows x 136 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df_wide = reshape_to_wide(df)\n",
    "df_wide.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd025b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline on 131 features...\n",
      "  -> Fitting Cycles_to_WW...\n",
      "  -> Fitting Cycles_to_HPC_SV...\n",
      "  -> Fitting Cycles_to_HPT_SV...\n",
      "------------------------------\n",
      "BASELINE SCORE: 23.400051\n",
      "Breakdown -> WW: 30.538735, HPC: 14.067881, HPT: 25.593536\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# --- 1. Scoring Function (From Challenge Spec) ---\n",
    "def time_weighted_error(y_true, y_pred, alpha=0.02, beta=1):\n",
    "    error = y_pred - y_true\n",
    "    # Late predictions (error > 0) penalized 2x more\n",
    "    weight = np.where(\n",
    "        error >= 0,\n",
    "        2 / (1 + alpha * y_true),\n",
    "        1 / (1 + alpha * y_true)\n",
    "    )\n",
    "    return weight * (error ** 2) * beta\n",
    "\n",
    "def evaluate_submission(df_true, df_pred):\n",
    "    # Calculate scores for all 3 targets independently\n",
    "    scores = []\n",
    "    \n",
    "    # 1. WW\n",
    "    s_ww = np.mean(time_weighted_error(\n",
    "        df_true['Cycles_to_WW'].values, df_pred['Cycles_to_WW'].values, \n",
    "        alpha=0.01, beta=1/float(df_true['Cycles_to_WW'].max())\n",
    "    ))\n",
    "    scores.append(s_ww)\n",
    "\n",
    "    # 2. HPC\n",
    "    s_hpc = np.mean(time_weighted_error(\n",
    "        df_true['Cycles_to_HPC_SV'].values, df_pred['Cycles_to_HPC_SV'].values, \n",
    "        alpha=0.01, beta=2/float(df_true['Cycles_to_HPC_SV'].max())\n",
    "    ))\n",
    "    scores.append(s_hpc)\n",
    "\n",
    "    # 3. HPT\n",
    "    s_hpt = np.mean(time_weighted_error(\n",
    "        df_true['Cycles_to_HPT_SV'].values, df_pred['Cycles_to_HPT_SV'].values, \n",
    "        alpha=0.01, beta=2/float(df_true['Cycles_to_HPT_SV'].max())\n",
    "    ))\n",
    "    scores.append(s_hpt)\n",
    "    \n",
    "    return np.mean(scores), scores\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "# Assuming 'df_wide' is your reshaped dataframe from the previous step\n",
    "# Features are everything except ID and Target columns\n",
    "features = [c for c in df_wide.columns if 'Sensed_' in c or 'Cumulative_' in c]\n",
    "targets = ['Cycles_to_WW', 'Cycles_to_HPC_SV', 'Cycles_to_HPT_SV']\n",
    "groups = df_wide['ESN']\n",
    "\n",
    "# Split engines: 80% engines for training, 20% for validation\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df_wide, groups=groups))\n",
    "\n",
    "X_train = df_wide.iloc[train_idx][features]\n",
    "y_train = df_wide.iloc[train_idx][targets]\n",
    "X_val = df_wide.iloc[val_idx][features]\n",
    "y_val = df_wide.iloc[val_idx][targets]\n",
    "\n",
    "# --- 3. Training (Multi-Output Strategy) ---\n",
    "# We train 3 separate XGBoost models. XGBoost is efficient enough to not need a single multi-output model.\n",
    "models = {}\n",
    "preds_val = pd.DataFrame(index=X_val.index)\n",
    "\n",
    "print(f\"Training Baseline on {len(features)} features...\")\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"  -> Fitting {target}...\")\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        objective='reg:squarederror', \n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train[target])\n",
    "    models[target] = model\n",
    "    preds_val[target] = model.predict(X_val)\n",
    "\n",
    "# --- 4. Evaluation ---\n",
    "final_score, component_scores = evaluate_submission(y_val, preds_val)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"BASELINE SCORE: {final_score:.6f}\")\n",
    "print(f\"Breakdown -> WW: {component_scores[0]:.6f}, HPC: {component_scores[1]:.6f}, HPT: {component_scores[2]:.6f}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b2e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing: Imputing missing values...\n",
      "\n",
      "--- Evaluating Models for Target: Cycles_to_WW ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/8 [00:00<?, ?it/s]/home/basta/Projects/PHM/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+08, tolerance: 5.077e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Models:  38%|███▊      | 3/8 [00:00<00:00,  5.73it/s]/home/basta/Projects/PHM/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+08, tolerance: 5.077e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Models: 100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Models for Target: Cycles_to_HPC_SV ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/8 [00:00<?, ?it/s]/home/basta/Projects/PHM/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.065e+09, tolerance: 3.445e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Models:  38%|███▊      | 3/8 [00:00<00:00,  5.82it/s]/home/basta/Projects/PHM/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.389e+09, tolerance: 3.445e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Models: 100%|██████████| 8/8 [00:05<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Models for Target: Cycles_to_HPT_SV ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/8 [00:00<?, ?it/s]/home/basta/Projects/PHM/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e+08, tolerance: 7.291e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Models:  38%|███▊      | 3/8 [00:00<00:00,  7.03it/s]/home/basta/Projects/PHM/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.376e+08, tolerance: 7.291e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Models: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top Models for Water Wash (WW) ===\n",
      "              Model  Competition_Score         RMSE\n",
      "6           XGBoost          26.296853   313.504563\n",
      "7          LightGBM          29.932155   293.308482\n",
      "4      DecisionTree          39.602777   302.777272\n",
      "5      RandomForest          42.074734   296.221905\n",
      "3        ElasticNet         534.706537  1066.573052\n",
      "1             Ridge         712.414913  1781.078701\n",
      "0  LinearRegression        2506.918921  3139.570743\n",
      "2             Lasso        6445.482322  4372.233861\n",
      "\n",
      "=== Top Models for HPC Shop Visit ===\n",
      "              Model  Competition_Score          RMSE\n",
      "5      RandomForest          13.536968    741.190331\n",
      "7          LightGBM          13.866620    738.960891\n",
      "6           XGBoost          16.004187    825.349787\n",
      "4      DecisionTree          21.114273   1064.152211\n",
      "1             Ridge         353.523798   6320.045423\n",
      "2             Lasso         911.096896   8632.236589\n",
      "0  LinearRegression        2674.850415  19861.489118\n",
      "3        ElasticNet       62608.096099  72252.717980\n",
      "\n",
      "=== Top Models for HPT Shop Visit ===\n",
      "              Model  Competition_Score          RMSE\n",
      "6           XGBoost          21.218595    426.815251\n",
      "7          LightGBM          23.805524    393.172226\n",
      "5      RandomForest          46.330937    580.172741\n",
      "4      DecisionTree          71.613931    802.119966\n",
      "0  LinearRegression        1081.383732   3712.830050\n",
      "2             Lasso        4649.222062   6875.466577\n",
      "1             Ridge        6210.836369   4826.908847\n",
      "3        ElasticNet       13590.964667  12226.968653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer # <--- Added this\n",
    "\n",
    "# Note: Ensure 'time_weighted_error' is defined from previous cells\n",
    "\n",
    "class LazyCompetitionEvaluator:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        # 1. Handle NaNs globally for consistency\n",
    "        # We fit the imputer ONLY on training data to avoid data leakage\n",
    "        print(\"Preprocessing: Imputing missing values...\")\n",
    "        self.imputer = SimpleImputer(strategy='mean')\n",
    "        \n",
    "        # We need to keep pandas index/columns for clarity, so we wrap the output\n",
    "        self.X_train = pd.DataFrame(\n",
    "            self.imputer.fit_transform(X_train), \n",
    "            columns=X_train.columns, \n",
    "            index=X_train.index\n",
    "        )\n",
    "        self.X_val = pd.DataFrame(\n",
    "            self.imputer.transform(X_val), \n",
    "            columns=X_val.columns, \n",
    "            index=X_val.index\n",
    "        )\n",
    "        \n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        # 2. Define Models\n",
    "        self.models = {\n",
    "            \"LinearRegression\": LinearRegression(),\n",
    "            \"Ridge\": Ridge(alpha=1.0),\n",
    "            \"Lasso\": Lasso(alpha=0.1),\n",
    "            # ElasticNet usually struggles with high dimensional raw data, but let's keep it\n",
    "            \"ElasticNet\": ElasticNet(alpha=0.1),\n",
    "            \"DecisionTree\": DecisionTreeRegressor(max_depth=5),\n",
    "            \"RandomForest\": RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42),\n",
    "            \"XGBoost\": xgb.XGBRegressor(n_estimators=100, max_depth=6, n_jobs=-1, random_state=42),\n",
    "            \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, max_depth=6, n_jobs=-1, random_state=42, verbose=-1),\n",
    "        }\n",
    "\n",
    "    def evaluate(self, target_col):\n",
    "        print(f\"\\n--- Evaluating Models for Target: {target_col} ---\")\n",
    "        \n",
    "        y_train_target = self.y_train[target_col]\n",
    "        y_val_target = self.y_val[target_col]\n",
    "        \n",
    "        # Dynamic weighting based on the target max life\n",
    "        max_cycles = float(self.y_val[target_col].max())\n",
    "        beta_weight = 2.0 if 'SV' in target_col else 1.0 \n",
    "        beta_val = beta_weight / max_cycles\n",
    "\n",
    "        target_results = []\n",
    "\n",
    "        for name, model in tqdm(self.models.items(), desc=\"Models\"):\n",
    "            start = time.time()\n",
    "            try:\n",
    "                model.fit(self.X_train, y_train_target)\n",
    "                preds = model.predict(self.X_val)\n",
    "                \n",
    "                # Competition Score\n",
    "                score = np.mean(time_weighted_error(\n",
    "                    y_val_target.values, \n",
    "                    preds, \n",
    "                    alpha=0.01, \n",
    "                    beta=beta_val\n",
    "                ))\n",
    "                \n",
    "                # RMSE for sanity check\n",
    "                rmse = np.sqrt(np.mean((y_val_target.values - preds)**2))\n",
    "                \n",
    "                target_results.append({\n",
    "                    \"Model\": name,\n",
    "                    \"Target\": target_col,\n",
    "                    \"Competition_Score\": score, # Lower is better\n",
    "                    \"RMSE\": rmse,\n",
    "                    \"Time_Sec\": time.time() - start\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed {name}: {e}\")\n",
    "\n",
    "        return pd.DataFrame(target_results).sort_values(by=\"Competition_Score\")\n",
    "\n",
    "# --- Execution ---\n",
    "# Re-instantiate the evaluator with the fix\n",
    "evaluator = LazyCompetitionEvaluator(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Run again\n",
    "results_ww = evaluator.evaluate('Cycles_to_WW')\n",
    "results_hpc = evaluator.evaluate('Cycles_to_HPC_SV')\n",
    "results_hpt = evaluator.evaluate('Cycles_to_HPT_SV')\n",
    "\n",
    "# Visualize Results\n",
    "print(\"\\n=== Top Models for Water Wash (WW) ===\")\n",
    "print(results_ww[['Model', 'Competition_Score', 'RMSE']])\n",
    "\n",
    "print(\"\\n=== Top Models for HPC Shop Visit ===\")\n",
    "print(results_hpc[['Model', 'Competition_Score', 'RMSE']])\n",
    "\n",
    "print(\"\\n=== Top Models for HPT Shop Visit ===\")\n",
    "print(results_hpt[['Model', 'Competition_Score', 'RMSE']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
